apiVersion: v1
kind: Service
metadata:
  name: sglang-embedding
  namespace: sglang-igw
spec:
  ports:
  - name: api
    port: 30000
    targetPort: 30000
  selector:
    app: sglang-worker
    model: qwen-embedding

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sglang-embedding
  namespace: sglang-igw
spec:
  replicas: 1
  selector:
    matchLabels:
      app: sglang-worker
      model: qwen-embedding
  template:
    metadata:
      labels:
        app: sglang-worker
        model: qwen-embedding
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "29000"
        prometheus.io/path: "/metrics"
    spec:
      # runtimeClassName: nvidia
      containers:
      - name: sglang-embedding
        image: lmsysorg/sglang:v0.5.7-runtime
        command: ["python3", "-m", "sglang.launch_server"]
        args:
          [
            "--model-path",
            "Qwen/Qwen3-Embedding-0.6B",
            "--is-embedding",
            "--host",
            "0.0.0.0",
            "--port",
            "30000",
            "--mem-fraction-static",
            "0.2",
            "--enable-metrics"
          ]
        resources:
          limits:
            cpu: 2
            memory: 8Gi
            # nvidia.com/gpu: 1
        volumeMounts:
        - name: hf-cache
          mountPath: /root/.cache/huggingface
        # - name: fi-cache
        #   mountPath: /root/.cache/flashinfer
        # - name: tt-cache
        #   mountPath: /root/.triton
        ports:
        - containerPort: 30000
        - containerPort: 29000
      volumes:
      - name: hf-cache
        persistentVolumeClaim:
          claimName: hf-cache-pvc
      # - name: fi-cache
      #   persistentVolumeClaim:
      #     claimName: fi-cache-pvc
      # - name: tt-cache
      #   persistentVolumeClaim:
      #     claimName: tt-cache-pvc
