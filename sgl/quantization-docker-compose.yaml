services:
  # SGLang Services with Prometheus metrics enabled
  modelopt-fp8:
    image: lmsysorg/sglang:${SGLANG_TAG:-latest-runtime}
    container_name: modelopt-fp8
    volumes:
      - quant_cache:/app/quantizations
      - fi_cache:/root/.cache/flashinfer
      - tt_cache:/root/.triton
    restart: always
    privileged: false
    entrypoint: python3 -m sglang.launch_server
    command: >
      --model-path /app/quantizations/models--modelopt_fp8
      --quantization modelopt_fp8
      --host 0.0.0.0
      --port 30000
      --attention-backend flashinfer
      --dtype bfloat16
      --kv-cache-dtype fp8_e4m3
      --mem-fraction-static 0.2
      --context-length 2048
      --max-total-tokens 2048
      --max-prefill-tokens 512
      --max-running-requests 1
      --enable-metrics
    ulimits:
      memlock: -1
      stack: 67108864
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:30000/health || exit 1"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - sglang-network
    labels:
      - "prometheus.io/scrape=true"
      - "prometheus.io/port=29000"
      - "prometheus.io/path=/metrics"

  modelopt-fp4:
    image: lmsysorg/sglang:${SGLANG_TAG:-latest-runtime}
    container_name: modelopt-fp4
    volumes:
      - quant_cache:/app/quantizations
      - fi_cache:/root/.cache/flashinfer
      - tt_cache:/root/.triton
    restart: always
    privileged: false
    entrypoint: python3 -m sglang.launch_server
    command: >
      --model-path /app/quantizations/models--modelopt_fp4
      --quantization modelopt_fp4
      --host 0.0.0.0
      --port 30000
      --attention-backend flashinfer
      --dtype bfloat16
      --kv-cache-dtype fp8_e4m3
      --mem-fraction-static 0.1
      --context-length 2048
      --max-total-tokens 2048
      --max-prefill-tokens 512
      --max-running-requests 1
      --enable-metrics
    ulimits:
      memlock: -1
      stack: 67108864
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:30000/health || exit 1"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - sglang-network
    labels:
      - "prometheus.io/scrape=true"
      - "prometheus.io/port=29000"
      - "prometheus.io/path=/metrics"

  autoround-w4a16:
    image: lmsysorg/sglang:${SGLANG_TAG:-latest-runtime}
    container_name: autoround-w4a16
    volumes:
      - quant_cache:/app/quantizations
      - fi_cache:/root/.cache/flashinfer
      - tt_cache:/root/.triton
    restart: always
    privileged: false
    entrypoint: python3 -m sglang.launch_server
    command: >
      --model-path /app/quantizations/models--autoround-w4a16
      --host 0.0.0.0
      --port 30000
      --attention-backend flashinfer
      --dtype bfloat16
      --kv-cache-dtype fp8_e4m3
      --mem-fraction-static 0.1
      --context-length 2048
      --max-total-tokens 2048
      --max-prefill-tokens 512
      --max-running-requests 1
      --enable-metrics
    ulimits:
      memlock: -1
      stack: 67108864
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:30000/health || exit 1"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - sglang-network
    labels:
      - "prometheus.io/scrape=true"
      - "prometheus.io/port=29000"
      - "prometheus.io/path=/metrics"

  autoround-awq:
    image: lmsysorg/sglang:${SGLANG_TAG:-latest-runtime}
    container_name: autoround-awq
    volumes:
      - quant_cache:/app/quantizations
      - fi_cache:/root/.cache/flashinfer
      - tt_cache:/root/.triton
    restart: always
    privileged: false
    entrypoint: python3 -m sglang.launch_server
    command: >
      --model-path /app/quantizations/models--autoround-awq
      --host 0.0.0.0
      --port 30000
      --attention-backend flashinfer
      --dtype float16
      --mem-fraction-static 0.1
      --context-length 2048
      --max-total-tokens 2048
      --max-prefill-tokens 512
      --max-running-requests 1
      --enable-metrics
    ulimits:
      memlock: -1
      stack: 67108864
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:30000/health || exit 1"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - sglang-network
    labels:
      - "prometheus.io/scrape=true"
      - "prometheus.io/port=29000"
      - "prometheus.io/path=/metrics"

  autoround-gptq:
    image: lmsysorg/sglang:${SGLANG_TAG:-latest-runtime}
    container_name: autoround-gptq
    volumes:
      - quant_cache:/app/quantizations
      - fi_cache:/root/.cache/flashinfer
      - tt_cache:/root/.triton
    restart: always
    privileged: false
    entrypoint: python3 -m sglang.launch_server
    command: >
      --model-path /app/quantizations/models--autoround-gptq
      --host 0.0.0.0
      --port 30000
      --attention-backend flashinfer
      --dtype float16
      --mem-fraction-static 0.1
      --context-length 2048
      --max-total-tokens 2048
      --max-prefill-tokens 512
      --max-running-requests 1
      --enable-metrics
    ulimits:
      memlock: -1
      stack: 67108864
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:30000/health || exit 1"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - sglang-network
    labels:
      - "prometheus.io/scrape=true"
      - "prometheus.io/port=29000"
      - "prometheus.io/path=/metrics"

  sglang-router:
    image: lmsysorg/sglang:${SGLANG_TAG:-latest-runtime}
    container_name: router
    restart: always
    ports:
      - 30000:30000      # Router API port
      - 29100:29000      # Router Prometheus metrics port
    entrypoint: python3 -m sglang_router.launch_router
    command: >
      --enable-igw
      --host 0.0.0.0
      --port 30000
      --policy cache_aware
      --prometheus-host 0.0.0.0
      --prometheus-port 29000
      --log-level info
    networks:
      - sglang-network
    depends_on:
      modelopt-fp8:
        condition: service_healthy
      modelopt-fp4:
        condition: service_healthy
      autoround-awq:
        condition: service_healthy
      autoround-gptq:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:30000/health || exit 1"]
    labels:
      - "prometheus.io/scrape=true"
      - "prometheus.io/port=29000"
      - "prometheus.io/path=/metrics"

  worker-register:
    image: curlimages/curl:latest
    container_name: sglang-worker-register
    depends_on:
      sglang-router:
        condition: service_healthy
    entrypoint: >
      sh -c "
        sleep 30
        curl -X POST http://sglang-router:30000/workers \\
          -H 'Content-Type: application/json' \\
          -d '{\"url\":\"http://modelopt-fp8:30000\",\"model_id\":\"modelopt-fp8\",\"priority\":10,\"labels\":{\"tier\":\"gold\"}}'

        curl -X POST http://sglang-router:30000/workers \\
          -H 'Content-Type: application/json' \\
          -d '{\"url\":\"http://modelopt-fp4:30000\",\"model_id\":\"modelopt-fp4\",\"priority\":10,\"labels\":{\"tier\":\"gold\"}}'

        curl -X POST http://sglang-router:30000/workers \\
          -H 'Content-Type: application/json' \\
          -d '{\"url\":\"http://autoround-w4a16:30000\",\"model_id\":\"autoround-w4a16\",\"priority\":10,\"labels\":{\"tier\":\"gold\"}}'

        curl -X POST http://sglang-router:30000/workers \\
          -H 'Content-Type: application/json' \\
          -d '{\"url\":\"http://autoround-awq:30000\",\"model_id\":\"autoround-awq\",\"priority\":10,\"labels\":{\"tier\":\"gold\"}}'

        curl -X POST http://sglang-router:30000/workers \\
          -H 'Content-Type: application/json' \\
          -d '{\"url\":\"http://autoround-gptq:30000\",\"model_id\":\"autoround-gptq\",\"priority\":10,\"labels\":{\"tier\":\"gold\"}}'

        echo 'Workers registered successfully'
      "
    network_mode: service:sglang-router

volumes:
  quant_cache:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./quantizations
  fi_cache:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: volume/flashinfer
  tt_cache:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: volume/triton

networks:
  sglang-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16